{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cardstdani/covid-classification-ml/blob/main/ModelNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HBsDPXc1PcEo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rKUvJI2pCnR"
      },
      "source": [
        "##**Data gathering and preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcayEf-oOoGG",
        "outputId": "0657eeff-2798-4ef3-873e-347d86977304"
      },
      "outputs": [],
      "source": [
        "DIR = r\"D:\\Engage\\Datasets\\Eye_Scans_Dataset\"\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(DIR, validation_split=0.1, subset=\"training\", seed=42, batch_size=32, smart_resize=True, image_size=(256, 256))\n",
        "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(DIR, validation_split=0.1, subset=\"validation\", seed=42, batch_size=32, smart_resize=True, image_size=(256, 256))\n",
        "\n",
        "classes = train_dataset.class_names\n",
        "numClasses = len(train_dataset.class_names)\n",
        "print(classes)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iikjEcDTgvKl"
      },
      "source": [
        "##<b>Data augmentation</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XyufTsjIwiFx"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O1Uu_Dyg0kI"
      },
      "source": [
        "##<b>Model Training</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ9l7_GE4OFC",
        "outputId": "bc07800b-539c-434d-c330-56ee38532662"
      },
      "outputs": [],
      "source": [
        "baseModel = tf.keras.applications.MobileNetV3Small(input_shape=(256, 256,3), weights='imagenet', include_top=False, classes=numClasses)\n",
        "last_output = baseModel.layers[-1].output\n",
        "x = tf.keras.layers.Dropout(0.5) (last_output)\n",
        "x = tf.keras.layers.GlobalMaxPooling2D() (last_output)\n",
        "x = tf.keras.layers.Dense(256, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(0.02), activity_regularizer=tf.keras.regularizers.l2(0.02),  kernel_initializer='he_normal')(x)\n",
        "x = tf.keras.layers.BatchNormalization() (x)\n",
        "x = tf.keras.layers.Dropout(0.45) (x)\n",
        "x = tf.keras.layers.Dense(numClasses, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=baseModel.input, outputs=x)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "epochs = 30\n",
        "timeDecay = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.001 * 1 / (1 + 10 * epoch))\n",
        "stepDecay = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.1 * 0.1**math.floor(epoch / 6))\n",
        "history = model.fit(train_dataset, validation_data=test_dataset, epochs=epochs, callbacks=[stepDecay])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sOWIIZeg653"
      },
      "source": [
        "<b>Model Architecture and Management</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()\n",
        "model.save('eyescanclassificationmodel.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLOzntcqZ5SE"
      },
      "source": [
        "##<b>Evaluation</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgN8eqKzpGdh"
      },
      "source": [
        "**One Image Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "EoqWrT3vjNsQ",
        "outputId": "6061d3b5-5cf7-4b5b-fdd3-79b9eee5dab8"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "img_data = requests.get(\"https://cdn0.scrvt.com/0e46935d037de4ec3888566275864b37/1800000007267893/5a55409c371b/v/f8eac2053bc7/x-ray-COVID-19-2_1800000007267893.jpg?nowebp=1\").content\n",
        "with open('img.jpg', 'wb') as handler:\n",
        "    handler.write(img_data)\n",
        "\n",
        "path = \"img.jpg\"\n",
        "path = \"D:\\COVID_19\\covid-classification-ml\\Covid19_Dataset\\Viral Pneumonia\\person1_virus_11.jpeg\"\n",
        "#path = \"/content/Covid19_Dataset/Normal/Normal-1000.png\"\n",
        "\n",
        "img = tf.keras.preprocessing.image.load_img(path, target_size=(256, 256))\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) \n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "plt.imshow(img)\n",
        "print(predictions[0]*100, \"\\n\", classes)\n",
        "print(\"Prediction: \", classes[np.argmax(predictions)], f\"{predictions[0][np.argmax(predictions)]*100}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "ModelNotebook.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "9caf4bdf9bff0018892f6c656404b5748dcef6f75dce33d518e58182bab2be7c"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('tf_gpu')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
